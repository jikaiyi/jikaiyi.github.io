# jemdoc: menu{MENU}{index.html}, nofooter  
== Welcome to Kaiyi Ji's Homepage

~~~
{}{img_left}{kaiyi.jpeg}{alt text}{175}{}{http://kaiyiji.github.io}
- Kaiyi Ji (吉凯意)
- Postdoctoral Research Fellow\n
- [https://eecs.engin.umich.edu  Department of Electrical Engineering and Computer Science] \n
- [https://umich.edu University of Michigan, Ann Arbor]\n
- Phone: (614) 330-2684 \n
- Email: kaiyiji at umich.edu 
~~~

== About Me
I am now a postdoctoral research fellow at the Electrical Engineering and Computer Science Department of the University of Michigan, Ann Arbor, working with
[https://leiying.engin.umich.edu Prof. Lei Ying]. 
I received my doctoral degree from the Electrical and Computer Engineering Department of The Ohio State University in August, 2021, under the supervision of [https://sites.google.com/view/yingbinliang/home Prof. Yingbin Liang]. 
I was a visiting student research collaborator at the department of Electrical Engineering, Princeton University working with [https://ece.princeton.edu/people/h-vincent-poor Prof. H. Vincent Poor]. 
Previously I obtained my B.E. degree from University of Science and Technology of China in 2016.

==  Research 
My major research interest lies in bilevel optimization for modern machine learning.
- On the theory side, I focus on new convergence theories for a variety of algorithms such as MAML, ANIL, approximated implicit differentiation (AID) and iterative differention (ITD) based bilevel optimizers, and provide rigorious explaination on exisitng training heuristics for bilevel optimization applications. 
I am also interested in charaterizing the fundamental limitations and optimality for bilevel optimization via developing new lower complexity bounds. 

- On the application side, I am interested in developing high-efficiency, scalable, and principled bilevel optimization algorithms for meta-learning, hyperparameter optimization and signal processing.  

I have also worked on the theory and application of gradient-free optimization, large-scale stochastic optimization, and generative models (GANs and VAE). 

== News! 
- I am rewarded as *expert reviewer* and *top 10% reviewer* for ICML 2021! Really honered! 
- Our paper on bilevel optimization has been accepted by ICML 2021. We provide new and comprehensive nonasympototic analysis for this area. 
We further propose a fast stochastic solver *stocBiO* with strong performance in applications such as hyperparameter optimization! Check our [https://arxiv.org/abs/2010.07962 paper] 
and [https://github.com/JunjieYang97/stocBiO code]!
- Our paper on theoretical analysis of MAML has been accepted by *JMLR 2021* with minor revision.
- Our paper on generalization error of GANs has been accepted by *Trans. on Information Theory (TIT) 2021*.
- I am really honored to receive the 2020/21 *Presidential Fellowship* at OSU, the highest award for graduate students! I am one of three winners of this award from ECE department this year. 
- I was awarded as a top 10% high-scoring reviewer for NeurIPS 2020. Thanks!







